{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tqdm import tqdm\n",
    "from skimage.transform import resize\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the label data from the csv file for each preprocessed mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>nodule_no</th>\n",
       "      <th>slice_no</th>\n",
       "      <th>original_image</th>\n",
       "      <th>mask_image</th>\n",
       "      <th>malignancy</th>\n",
       "      <th>is_cancer</th>\n",
       "      <th>is_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>LIDC-IDRI-0001/0001_NI000_slice000</td>\n",
       "      <td>LIDC-IDRI-0001/0001_MA000_slice000</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>LIDC-IDRI-0001/0001_NI000_slice001</td>\n",
       "      <td>LIDC-IDRI-0001/0001_MA000_slice001</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>LIDC-IDRI-0001/0001_NI000_slice002</td>\n",
       "      <td>LIDC-IDRI-0001/0001_MA000_slice002</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>LIDC-IDRI-0001/0001_NI000_slice003</td>\n",
       "      <td>LIDC-IDRI-0001/0001_MA000_slice003</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>LIDC-IDRI-0001/0001_NI000_slice004</td>\n",
       "      <td>LIDC-IDRI-0001/0001_MA000_slice004</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id  nodule_no  slice_no                      original_image  \\\n",
       "0           1          0         0  LIDC-IDRI-0001/0001_NI000_slice000   \n",
       "1           1          0         1  LIDC-IDRI-0001/0001_NI000_slice001   \n",
       "2           1          0         2  LIDC-IDRI-0001/0001_NI000_slice002   \n",
       "3           1          0         3  LIDC-IDRI-0001/0001_NI000_slice003   \n",
       "4           1          0         4  LIDC-IDRI-0001/0001_NI000_slice004   \n",
       "\n",
       "                           mask_image  malignancy is_cancer  is_clean  \n",
       "0  LIDC-IDRI-0001/0001_MA000_slice000           5      True     False  \n",
       "1  LIDC-IDRI-0001/0001_MA000_slice001           5      True     False  \n",
       "2  LIDC-IDRI-0001/0001_MA000_slice002           5      True     False  \n",
       "3  LIDC-IDRI-0001/0001_MA000_slice003           5      True     False  \n",
       "4  LIDC-IDRI-0001/0001_MA000_slice004           5      True     False  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"Path to 'meta_info.csv' file\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing the csv file to make it suitable for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the images without any nodules\n",
    "data = data[data['is_clean'] != True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantifying the cancer/benign outcome classes \n",
    "data[\"is_cancer\"] = data['is_cancer'].map({'Ambiguous':-1, 'True':1,'False':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with the image filename and label\n",
    "mask_malignancy_dict = dict(zip(data['mask_image'], data['malignancy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LIDC-IDRI-1012/1012_MA000_slice002'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames = list(mask_malignancy_dict.keys())\n",
    "labels = list(mask_malignancy_dict.values())\n",
    "filenames[len(filenames)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(labels), min(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = []\n",
    "files = []\n",
    "for n, val in enumerate(filenames):\n",
    "    parts = val.split('/')\n",
    "    folders.append(parts[0])\n",
    "    files.append(parts[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "path = \"Path to mask folder only\"\n",
    "\n",
    "for fol, fil in zip(folders, files):\n",
    "    try:\n",
    "        X.append(np.load(path+fol+\"\\\\\"+fil+\".npy\"))\n",
    "    except FileNotFoundError:\n",
    "        continue\n",
    "for n in range(0,len(labels)):\n",
    "    Y.append(labels[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train : 6400\n",
      "X_test : 1600\n",
      "y_train : 6400\n",
      "y_test : 1600\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# Get the number of malignancy classes\n",
    "num_classes = len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.zeros((len(X_train), 512, 512, 1))\n",
    "test_x = np.zeros((len(X_test), 512, 512, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = np.array(y_train)\n",
    "test_y = np.array(y_test)\n",
    "train_y = np.reshape(train_y, (len(train_y),1)) # reshape the label array\n",
    "test_y = np.reshape(test_y, (len(test_y),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the mask image npy files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 6400/6400 [00:01<00:00, 3325.41it/s]\n"
     ]
    }
   ],
   "source": [
    "for n, img in tqdm(enumerate(X_train), total=len(X_train)):\n",
    "    img = np.reshape(img, (512, 512, 1))\n",
    "    train_x[n] = img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1600/1600 [00:00<00:00, 3487.76it/s]\n"
     ]
    }
   ],
   "source": [
    "for n, test_img in tqdm(enumerate(X_test), total=len(X_test)):\n",
    "    test_img = np.reshape(test_img, (512, 512, 1))\n",
    "    test_x[n] = test_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6400, 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subtract 1 from the labels to shift the range to [0, 4] due the use of categorical_crossentropy\n",
    "train_y = train_y - 1\n",
    "test_y = test_y - 1\n",
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding the labels\n",
    "train_y_encoded = to_categorical(train_y, num_classes=5)\n",
    "test_y_encoded = to_categorical(test_y, num_classes=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir='logs')\n",
    "checkpoint = ModelCheckpoint('help.h5', save_best_only=True, verbose=1)\n",
    "early_stopping = EarlyStopping(patience=5, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(factor=0.1, patience=2, verbose=1)\n",
    "callbacks = [checkpoint, early_stopping, reduce_lr, tensorboard]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_classification_model(input_shape, num_classes):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "\n",
    "    conv1 = layers.Conv2D(32, 3, activation='relu', padding='same')(inputs)\n",
    "    conv1 = layers.BatchNormalization()(conv1)\n",
    "    conv1 = layers.Conv2D(32, 3, activation='relu', padding='same')(conv1)\n",
    "    conv1 = layers.BatchNormalization()(conv1)\n",
    "    pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = layers.Conv2D(64, 3, activation='relu', padding='same')(pool1)\n",
    "    conv2 = layers.BatchNormalization()(conv2)\n",
    "    conv2 = layers.Conv2D(64, 3, activation='relu', padding='same')(conv2)\n",
    "    conv2 = layers.BatchNormalization()(conv2)\n",
    "    pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = layers.Conv2D(128, 3, activation='relu', padding='same')(pool2)\n",
    "    conv3 = layers.BatchNormalization()(conv3)\n",
    "    conv3 = layers.Conv2D(128, 3, activation='relu', padding='same')(conv3)\n",
    "    conv3 = layers.BatchNormalization()(conv3)\n",
    "    pool3 = layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    flatten = layers.Flatten()(pool3)\n",
    "\n",
    "    dense1 = layers.Dense(256, activation='relu')(flatten)\n",
    "    dense1 = layers.BatchNormalization()(dense1)\n",
    "    dense2 = layers.Dense(128, activation='relu')(dense1)\n",
    "    dense2 = layers.BatchNormalization()(dense2)\n",
    "\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(dense2)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "input_shape = (512, 512, 1)\n",
    "num_classes = 5 \n",
    "\n",
    "model = create_classification_model(input_shape, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_x, train_y_encoded, batch_size=8, epochs=30, validation_data=(val_x, val_y_encoded), callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_x, test_y_encoded)\n",
    "print('Test Loss:', test_loss)\n",
    "print('Test Accuracy:', test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
