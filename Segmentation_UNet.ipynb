{"cells":[{"cell_type":"code","execution_count":null,"id":"93d2f638","metadata":{"id":"93d2f638"},"outputs":[],"source":["from glob import glob\n","import tensorflow as tf\n","from tensorflow.keras import layers\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from skimage.transform import resize\n","from tqdm import tqdm"]},{"cell_type":"markdown","id":"54921bef","metadata":{"id":"54921bef"},"source":["Get the Images and Masks from the filepath"]},{"cell_type":"code","execution_count":null,"id":"9b1d80a3","metadata":{"id":"9b1d80a3"},"outputs":[],"source":["image_filenames = glob(\"Path to LIDC-IDRI Preprocessed Image File\")\n","mask_filenames = glob(\"Path to LIDC-IDRI Preprocessd Mask File\")"]},{"cell_type":"code","execution_count":null,"id":"459dc60e","metadata":{"id":"459dc60e"},"outputs":[],"source":["# Creating zeros array to saved loaded files after reshaping\n","image = np.zeros((len(image_filenames),512,512,1))\n","mask = np.zeros((len(mask_filenames),512,512,1))"]},{"cell_type":"code","execution_count":null,"id":"4ff542fc","metadata":{"collapsed":true,"id":"4ff542fc","outputId":"a1d1d313-a380-42a4-da2b-68055cced77c"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|███████████████████████████████████████████████████████████████████████████████| 500/500 [00:01<00:00, 391.79it/s]\n"]}],"source":["# Loading the npy files and storing them in image array\n","for n, img in tqdm(enumerate(image_filenames),total=len(image_filenames)):\n","    img = np.load(img)\n","    img = np.reshape(img, (512,512,1))\n","    image[n] = img"]},{"cell_type":"code","execution_count":null,"id":"7d996936","metadata":{"collapsed":true,"id":"7d996936","outputId":"c0f165e7-876b-4c90-827f-d815ebc9c555"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|███████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 892.48it/s]\n"]}],"source":["# Loading the npy files and storing them in mask array\n","for n, img in tqdm(enumerate(mask_filenames),total=len(mask_filenames)):\n","    img = np.load(img)\n","    img = np.reshape(img, (512,512,1))\n","    mask[n] = img"]},{"cell_type":"markdown","id":"39cf1f8a","metadata":{"id":"39cf1f8a"},"source":["Train, Test, Validation Split"]},{"cell_type":"code","execution_count":null,"id":"066d6bb8","metadata":{"id":"066d6bb8"},"outputs":[],"source":["train_x, test_x, train_y, test_y = train_test_split(image, mask, test_size=0.2, random_state=42)\n","train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size=0.2, random_state=42)"]},{"cell_type":"markdown","id":"c81cd2c8","metadata":{"id":"c81cd2c8"},"source":["Dice Coefficient Loss Function"]},{"cell_type":"code","execution_count":null,"id":"993d24c6","metadata":{"id":"993d24c6"},"outputs":[],"source":["def dice_coef(y_true, y_pred, smooth=1):\n","    intersection = tf.reduce_sum(y_true * y_pred)\n","    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred)\n","    dice = (2. * intersection + smooth) / (union + smooth)\n","    return dice\n","\n","def dice_coef_loss(y_true, y_pred):\n","    loss = 1 - dice_coef(y_true, y_pred)\n","    return loss\n"]},{"cell_type":"markdown","id":"4ffc68e4","metadata":{"id":"4ffc68e4"},"source":["Conv-Unet Model"]},{"cell_type":"code","execution_count":null,"id":"f1eb3675","metadata":{"scrolled":true,"id":"f1eb3675"},"outputs":[],"source":["def conv_block(inputs, filters, kernel_size=3, activation='relu', padding='same'):\n","    conv = layers.Conv2D(filters, kernel_size, activation=activation, padding=padding)(inputs)\n","    conv = layers.BatchNormalization()(conv)\n","    conv = layers.Conv2D(filters, kernel_size, activation=activation, padding=padding)(conv)\n","    conv = layers.BatchNormalization()(conv)\n","    return conv\n","\n","def convunet_model(input_shape):\n","    inputs = tf.keras.Input(shape=input_shape)\n","\n","    # Contracting Path\n","    conv1 = conv_block(inputs, 32)\n","    pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n","\n","    conv2 = conv_block(pool1, 64)\n","    pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n","\n","    conv3 = conv_block(pool2, 128)\n","    pool3 = layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n","\n","    conv4 = conv_block(pool3, 256)\n","    pool4 = layers.MaxPooling2D(pool_size=(2, 2))(conv4)\n","\n","    conv5 = conv_block(pool4, 512)\n","\n","    # Expanding Path\n","    up6 = layers.Conv2DTranspose(256, 2, strides=(2, 2), padding='same')(conv5)\n","    up6 = layers.concatenate([up6, conv4])\n","    conv6 = conv_block(up6, 256)\n","\n","    up7 = layers.Conv2DTranspose(128, 2, strides=(2, 2), padding='same')(conv6)\n","    up7 = layers.concatenate([up7, conv3])\n","    conv7 = conv_block(up7, 128)\n","\n","    up8 = layers.Conv2DTranspose(64, 2, strides=(2, 2), padding='same')(conv7)\n","    up8 = layers.concatenate([up8, conv2])\n","    conv8 = conv_block(up8, 64)\n","\n","    up9 = layers.Conv2DTranspose(32, 2, strides=(2, 2), padding='same')(conv8)\n","    up9 = layers.concatenate([up9, conv1])\n","    conv9 = conv_block(up9, 32)\n","\n","    outputs = layers.Conv2D(1, 1, activation='sigmoid')(conv9)\n","\n","    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n","    return model\n","\n","input_shape = (512, 512, 1)\n","\n","model = convunet_model(input_shape)\n","\n","optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n","\n","model.compile(optimizer=optimizer, loss=dice_coef_loss, metrics=[dice_coef])"]},{"cell_type":"code","execution_count":null,"id":"2de2b9b7","metadata":{"collapsed":true,"id":"2de2b9b7","outputId":"c9090080-f531-491c-dbbc-1ed0ada8787d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","80/80 [==============================] - ETA: 0s - loss: 0.9934 - dice_coef: 0.0066\n","Epoch 1: val_loss improved from inf to 0.97838, saving model to newmodelv5.h5\n","80/80 [==============================] - 44s 412ms/step - loss: 0.9934 - dice_coef: 0.0066 - val_loss: 0.9784 - val_dice_coef: 0.0216 - lr: 0.0010\n","Epoch 2/20\n","80/80 [==============================] - ETA: 0s - loss: 0.9881 - dice_coef: 0.0119\n","Epoch 2: val_loss did not improve from 0.97838\n","80/80 [==============================] - 33s 419ms/step - loss: 0.9881 - dice_coef: 0.0119 - val_loss: 0.9983 - val_dice_coef: 0.0017 - lr: 0.0010\n","Epoch 3/20\n","80/80 [==============================] - ETA: 0s - loss: 0.9819 - dice_coef: 0.0181\n","Epoch 3: val_loss did not improve from 0.97838\n","80/80 [==============================] - 34s 427ms/step - loss: 0.9819 - dice_coef: 0.0181 - val_loss: 0.9921 - val_dice_coef: 0.0079 - lr: 0.0010\n","Epoch 4/20\n","80/80 [==============================] - ETA: 0s - loss: 0.9757 - dice_coef: 0.0243\n","Epoch 4: val_loss did not improve from 0.97838\n","\n","Epoch 4: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n","80/80 [==============================] - 34s 429ms/step - loss: 0.9757 - dice_coef: 0.0243 - val_loss: 0.9985 - val_dice_coef: 0.0015 - lr: 0.0010\n","Epoch 5/20\n","80/80 [==============================] - ETA: 0s - loss: 0.9516 - dice_coef: 0.0484\n","Epoch 5: val_loss did not improve from 0.97838\n","80/80 [==============================] - 35s 433ms/step - loss: 0.9516 - dice_coef: 0.0484 - val_loss: 0.9983 - val_dice_coef: 0.0017 - lr: 1.0000e-04\n","Epoch 6/20\n","80/80 [==============================] - ETA: 0s - loss: 0.9203 - dice_coef: 0.0797\n","Epoch 6: val_loss improved from 0.97838 to 0.96551, saving model to newmodelv5.h5\n","80/80 [==============================] - 35s 442ms/step - loss: 0.9203 - dice_coef: 0.0797 - val_loss: 0.9655 - val_dice_coef: 0.0345 - lr: 1.0000e-04\n","Epoch 7/20\n","80/80 [==============================] - ETA: 0s - loss: 0.8707 - dice_coef: 0.1293\n","Epoch 7: val_loss improved from 0.96551 to 0.96191, saving model to newmodelv5.h5\n","80/80 [==============================] - 36s 445ms/step - loss: 0.8707 - dice_coef: 0.1293 - val_loss: 0.9619 - val_dice_coef: 0.0381 - lr: 1.0000e-04\n","Epoch 8/20\n","80/80 [==============================] - ETA: 0s - loss: 0.8230 - dice_coef: 0.1770\n","Epoch 8: val_loss improved from 0.96191 to 0.88765, saving model to newmodelv5.h5\n","80/80 [==============================] - 36s 445ms/step - loss: 0.8230 - dice_coef: 0.1770 - val_loss: 0.8877 - val_dice_coef: 0.1123 - lr: 1.0000e-04\n","Epoch 9/20\n","80/80 [==============================] - ETA: 0s - loss: 0.7727 - dice_coef: 0.2273\n","Epoch 9: val_loss improved from 0.88765 to 0.76695, saving model to newmodelv5.h5\n","80/80 [==============================] - 36s 450ms/step - loss: 0.7727 - dice_coef: 0.2273 - val_loss: 0.7670 - val_dice_coef: 0.2330 - lr: 1.0000e-04\n","Epoch 10/20\n","80/80 [==============================] - ETA: 0s - loss: 0.7323 - dice_coef: 0.2677\n","Epoch 10: val_loss did not improve from 0.76695\n","80/80 [==============================] - 36s 448ms/step - loss: 0.7323 - dice_coef: 0.2677 - val_loss: 0.8801 - val_dice_coef: 0.1199 - lr: 1.0000e-04\n","Epoch 11/20\n","80/80 [==============================] - ETA: 0s - loss: 0.6990 - dice_coef: 0.3010\n","Epoch 11: val_loss improved from 0.76695 to 0.74671, saving model to newmodelv5.h5\n","80/80 [==============================] - 36s 453ms/step - loss: 0.6990 - dice_coef: 0.3010 - val_loss: 0.7467 - val_dice_coef: 0.2533 - lr: 1.0000e-04\n","Epoch 12/20\n","80/80 [==============================] - ETA: 0s - loss: 0.6688 - dice_coef: 0.3312\n","Epoch 12: val_loss did not improve from 0.74671\n","80/80 [==============================] - 36s 451ms/step - loss: 0.6688 - dice_coef: 0.3312 - val_loss: 0.7725 - val_dice_coef: 0.2275 - lr: 1.0000e-04\n","Epoch 13/20\n","80/80 [==============================] - ETA: 0s - loss: 0.6333 - dice_coef: 0.3667\n","Epoch 13: val_loss did not improve from 0.74671\n","80/80 [==============================] - 36s 453ms/step - loss: 0.6333 - dice_coef: 0.3667 - val_loss: 0.8411 - val_dice_coef: 0.1589 - lr: 1.0000e-04\n","Epoch 14/20\n","80/80 [==============================] - ETA: 0s - loss: 0.6103 - dice_coef: 0.3897\n","Epoch 14: val_loss improved from 0.74671 to 0.67060, saving model to newmodelv5.h5\n","80/80 [==============================] - 37s 457ms/step - loss: 0.6103 - dice_coef: 0.3897 - val_loss: 0.6706 - val_dice_coef: 0.3294 - lr: 1.0000e-04\n","Epoch 15/20\n","80/80 [==============================] - ETA: 0s - loss: 0.5765 - dice_coef: 0.4235\n","Epoch 15: val_loss did not improve from 0.67060\n","80/80 [==============================] - 36s 452ms/step - loss: 0.5765 - dice_coef: 0.4235 - val_loss: 0.7079 - val_dice_coef: 0.2921 - lr: 1.0000e-04\n","Epoch 16/20\n","80/80 [==============================] - ETA: 0s - loss: 0.5576 - dice_coef: 0.4424\n","Epoch 16: val_loss improved from 0.67060 to 0.58614, saving model to newmodelv5.h5\n","80/80 [==============================] - 37s 457ms/step - loss: 0.5576 - dice_coef: 0.4424 - val_loss: 0.5861 - val_dice_coef: 0.4139 - lr: 1.0000e-04\n","Epoch 17/20\n","80/80 [==============================] - ETA: 0s - loss: 0.5762 - dice_coef: 0.4238\n","Epoch 17: val_loss improved from 0.58614 to 0.52058, saving model to newmodelv5.h5\n","80/80 [==============================] - 37s 458ms/step - loss: 0.5762 - dice_coef: 0.4238 - val_loss: 0.5206 - val_dice_coef: 0.4794 - lr: 1.0000e-04\n","Epoch 18/20\n","80/80 [==============================] - ETA: 0s - loss: 0.5032 - dice_coef: 0.4968\n","Epoch 18: val_loss improved from 0.52058 to 0.51890, saving model to newmodelv5.h5\n","80/80 [==============================] - 37s 457ms/step - loss: 0.5032 - dice_coef: 0.4968 - val_loss: 0.5189 - val_dice_coef: 0.4811 - lr: 1.0000e-04\n","Epoch 19/20\n","80/80 [==============================] - ETA: 0s - loss: 0.5031 - dice_coef: 0.4969\n","Epoch 19: val_loss improved from 0.51890 to 0.44250, saving model to newmodelv5.h5\n","80/80 [==============================] - 37s 458ms/step - loss: 0.5031 - dice_coef: 0.4969 - val_loss: 0.4425 - val_dice_coef: 0.5575 - lr: 1.0000e-04\n","Epoch 20/20\n","80/80 [==============================] - ETA: 0s - loss: 0.5000 - dice_coef: 0.5000\n","Epoch 20: val_loss did not improve from 0.44250\n","80/80 [==============================] - 36s 456ms/step - loss: 0.5000 - dice_coef: 0.5000 - val_loss: 0.7433 - val_dice_coef: 0.2567 - lr: 1.0000e-04\n"]}],"source":["# Defining checkpoints\n","checkpoint = ModelCheckpoint('unetmodeltest.h5', save_best_only=True, verbose=1)\n","early_stopping = EarlyStopping(patience=5, verbose=1)\n","reduce_lr = ReduceLROnPlateau(factor=0.1, patience=3, verbose=1)\n","callbacks = [checkpoint, early_stopping, reduce_lr]\n","\n","# Train the model\n","history = model.fit(train_x, train_y, validation_data=(val_x, val_y), batch_size=4, epochs=20, callbacks=callbacks)\n"]},{"cell_type":"code","execution_count":null,"id":"b5cf3938","metadata":{"collapsed":true,"id":"b5cf3938","outputId":"d3e28612-a3f3-4053-bab8-875ca487bee4"},"outputs":[{"ename":"ResourceExhaustedError","evalue":"Graph execution error:\n\nDetected at node 'model/batch_normalization_2/FusedBatchNormV3' defined at (most recent call last):\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n      app.start()\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\akash\\AppData\\Local\\Temp\\ipykernel_1136\\220959365.py\", line 1, in <module>\n      test_loss, test_dice_coef = model.evaluate(test_x, test_y)\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1947, in evaluate\n      tmp_logs = self.test_function(iterator)\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1727, in test_function\n      return step_function(self, iterator)\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1713, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1701, in run_step\n      outputs = model.test_step(data)\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1665, in test_step\n      y_pred = self(x, training=False)\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 850, in call\n      outputs = self._fused_batch_norm(inputs, training=training)\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 660, in _fused_batch_norm\n      output, mean, variance = control_flow_util.smart_cond(\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\utils\\control_flow_util.py\", line 108, in smart_cond\n      return tf.__internal__.smart_cond.smart_cond(\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 649, in _fused_batch_norm_inference\n      return tf.compat.v1.nn.fused_batch_norm(\nNode: 'model/batch_normalization_2/FusedBatchNormV3'\nOOM when allocating tensor with shape[32,64,256,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model/batch_normalization_2/FusedBatchNormV3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_test_function_21127]","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)","Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m test_loss, test_dice_coef \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_x\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_y\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Loss:\u001b[39m\u001b[38;5;124m\"\u001b[39m, test_loss)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Dice Coefficient:\u001b[39m\u001b[38;5;124m\"\u001b[39m, test_dice_coef)\n","File \u001b[1;32mc:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[1;32mc:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'model/batch_normalization_2/FusedBatchNormV3' defined at (most recent call last):\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n      app.start()\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\akash\\AppData\\Local\\Temp\\ipykernel_1136\\220959365.py\", line 1, in <module>\n      test_loss, test_dice_coef = model.evaluate(test_x, test_y)\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1947, in evaluate\n      tmp_logs = self.test_function(iterator)\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1727, in test_function\n      return step_function(self, iterator)\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1713, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1701, in run_step\n      outputs = model.test_step(data)\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1665, in test_step\n      y_pred = self(x, training=False)\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 850, in call\n      outputs = self._fused_batch_norm(inputs, training=training)\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 660, in _fused_batch_norm\n      output, mean, variance = control_flow_util.smart_cond(\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\utils\\control_flow_util.py\", line 108, in smart_cond\n      return tf.__internal__.smart_cond.smart_cond(\n    File \"c:\\users\\akash\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 649, in _fused_batch_norm_inference\n      return tf.compat.v1.nn.fused_batch_norm(\nNode: 'model/batch_normalization_2/FusedBatchNormV3'\nOOM when allocating tensor with shape[32,64,256,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model/batch_normalization_2/FusedBatchNormV3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_test_function_21127]"]}],"source":["test_loss, test_dice_coef = model.evaluate(test_x, test_y)\n","print(\"Test Loss:\", test_loss)\n","print(\"Test Dice Coefficient:\", test_dice_coef)"]},{"cell_type":"code","execution_count":null,"id":"72ece0a0","metadata":{"collapsed":true,"id":"72ece0a0","outputId":"bc44db5f-3ca9-4f7c-daea-8f01f7f7fdf3"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 23). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Assets written to: unetmodelnewv2\\assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: unetmodelnewv2\\assets\n"]}],"source":["model.save(\"unetmodel\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}